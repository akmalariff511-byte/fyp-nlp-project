{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPduYI3j30mw6fCSXon+bX5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akmalariff511-byte/fyp-nlp-project/blob/main/Copy_of_Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "--XHZSw9Y73z",
        "outputId": "26ad5546-09b1-4058-ae6f-8d3a4bf15296"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2971517729.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# ====== LOAD MODEL & TOKENIZER ======\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, render_template_string\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# ====== LOAD MODEL & TOKENIZER ======\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# reverse maps\n",
        "id2target  = {v:k for k,v in target2id.items()}\n",
        "id2emotion = {v:k for k,v in emotion2id.items()}\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "    x = x - np.max(x)\n",
        "    ex = np.exp(x)\n",
        "    return ex / np.sum(ex)\n",
        "\n",
        "def predict_text(text):\n",
        "    enc = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(input_ids=enc[\"input_ids\"], attention_mask=enc[\"attention_mask\"])\n",
        "\n",
        "    p_politic = float(sigmoid(out[\"p\"].cpu().numpy())[0])\n",
        "    p_hate    = float(sigmoid(out[\"h\"].cpu().numpy())[0])\n",
        "\n",
        "    target_logits  = out[\"t\"].cpu().numpy()[0]\n",
        "    emotion_logits = out[\"e\"].cpu().numpy()[0]\n",
        "\n",
        "    target_probs  = softmax(target_logits)\n",
        "    emotion_probs = softmax(emotion_logits)\n",
        "\n",
        "    return {\n",
        "        \"politic\": (\"Political\" if p_politic >= 0.5 else \"Non-political\", round(p_politic, 3)),\n",
        "        \"hate\": (\"Hate\" if p_hate >= 0.5 else \"Non-hate\", round(p_hate, 3)),\n",
        "        \"target\": (id2target[int(np.argmax(target_probs))], round(float(np.max(target_probs)), 3)),\n",
        "        \"emotion\": (id2emotion[int(np.argmax(emotion_probs))], round(float(np.max(emotion_probs)), 3))\n",
        "    }\n",
        "\n",
        "# ====== SIMPLE UI ======\n",
        "HTML = \"\"\"\n",
        "<!doctype html>\n",
        "<title>Political Text Analysis System</title>\n",
        "<h2>Political Text Analysis System</h2>\n",
        "\n",
        "<form method=\"post\">\n",
        "  <textarea name=\"text\" rows=\"4\" cols=\"80\" placeholder=\"Enter text here...\"></textarea><br><br>\n",
        "  <input type=\"submit\" value=\"Analyze\">\n",
        "</form>\n",
        "\n",
        "{% if result %}\n",
        "<hr>\n",
        "<h3>Result</h3>\n",
        "<ul>\n",
        "  <li><b>Political Topic:</b> {{ result.politic[0] }} ({{ result.politic[1] }})</li>\n",
        "  <li><b>Hate Speech:</b> {{ result.hate[0] }} ({{ result.hate[1] }})</li>\n",
        "  <li><b>Target:</b> {{ result.target[0] }} ({{ result.target[1] }})</li>\n",
        "  <li><b>Emotion:</b> {{ result.emotion[0] }} ({{ result.emotion[1] }})</li>\n",
        "</ul>\n",
        "{% endif %}\n",
        "\"\"\"\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def index():\n",
        "    result = None\n",
        "    if request.method == \"POST\":\n",
        "        text = request.form[\"text\"]\n",
        "        result = predict_text(text)\n",
        "    return render_template_string(HTML, result=result)\n",
        "\n",
        "app.run(host=\"0.0.0.0\", port=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install flask safetensors transformers\n"
      ],
      "metadata": {
        "id": "jYex04xgtiBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/app.py\n"
      ],
      "metadata": {
        "id": "pmbERhsbtoIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pyngrok\n"
      ],
      "metadata": {
        "id": "HOAb8zXUtpZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content | grep app\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpfEsCgZuUMj",
        "outputId": "9a84e73d-ef60-40bd-a5b6-a126e705e6b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app2.py\n",
            "app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/app2.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJp2pgcUuXlc",
        "outputId": "ffedd783-2e8f-4d1d-fd79-d5ad839a2cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 135kB/s]\n",
            "config.json: 100% 615/615 [00:00<00:00, 3.77MB/s]\n",
            "sentencepiece.bpe.model: 100% 5.07M/5.07M [00:00<00:00, 23.3MB/s]\n",
            "tokenizer.json: 100% 9.10M/9.10M [00:00<00:00, 19.5MB/s]\n",
            "2025-12-30 10:07:12.469331: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-30 10:07:12.478692: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-30 10:07:12.501420: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767089232.545791   23101 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767089232.558494   23101 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767089232.585723   23101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767089232.585776   23101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767089232.585786   23101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767089232.585793   23101 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-30 10:07:12.595057: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "model.safetensors: 100% 1.12G/1.12G [00:22<00:00, 50.3MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/app2.py\", line 53, in <module>\n",
            "    raise FileNotFoundError(f\"No model weights found in {MODEL_DIR}\")\n",
            "FileNotFoundError: No model weights found in /content/drive/MyDrive/akmal_fyp/xlmr_multitask_out/best_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la /content/drive/MyDrive/akmal_fyp/xlmr_multitask_out/best_model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKzHyjXrvB_y",
        "outputId": "e46e147f-1828-43e6-ed9e-2450a15313b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/drive/MyDrive/akmal_fyp/xlmr_multitask_out/best_model': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGovpGSMvjLU",
        "outputId": "927dedbc-c78b-4cf2-fad4-759970a2c098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive\n",
        "!ls /content/drive/MyDrive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGHxHKGOvrBY",
        "outputId": "bc6f8d80-cb87-402f-d8db-aeeb7b7ace7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDrive\n",
            "'Activity Diagram.drawio'\n",
            " akmal_fyp\n",
            "'CHAPTER 1.2&1.3- MOLE CONCEPT.gdoc'\n",
            "'Chapter 2 (1).gdoc'\n",
            "'Chapter 2.gdoc'\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            "'Copy of Mini Proposal Outline Form (Taklimat).docx'\n",
            "'CSC404 PROGRAMMING  II.gdoc'\n",
            "'csp akmal.gdoc'\n",
            "'Edited - extra questions FT1A akmal.pdf'\n",
            "'eksperimen 1physics akmal.gdoc'\n",
            "'extra question_EMPIRICAL FORMULA.gdoc'\n",
            "'extra question_MASS SPECTRUM.gdoc'\n",
            "'extra questions FT1A akmal.pdf'\n",
            " f74857401665e0d0bc400ae013ca82c53e65db58cee42b516b304fe960a51316.pdf\n",
            " facebook_comments_processed_output.xlsx\n",
            "'Getting started.pdf'\n",
            "'KOLEKSI STRUKTUR 2020 (1).doc'\n",
            "'KOLEKSI STRUKTUR 2020 (2).doc'\n",
            "'KOLEKSI STRUKTUR 2020.doc'\n",
            "'MODULE 1 AOS CHEMISTRY.pdf'\n",
            " Screenshot_20210930_225437_my.com.maybank2u.m2umobile.jpg\n",
            " Screenshot_20210930_225605.jpg\n",
            "'slip e pendaftaran  (1).pdf'\n",
            "'slip e pendaftaran .pdf'\n",
            "'TUTORIAL 1.gdoc'\n",
            "'TUTORIAL  2.0-ATOMIC STRUCTURE.gdoc'\n",
            "'TUTORIAL 2.gdoc'\n",
            "'UNIVERSITI TEKNOLOGI MARA.gdoc'\n",
            "'Untitled Diagram.drawio'\n",
            "'Untitled form.gform'\n",
            "'Untitled Library.xml'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/akmal_fyp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-VkLzVQv1WY",
        "outputId": "6e9990ce-37c5-4fd0-c746-b74de02b20a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL_EMOTION_MERGED_FINAL_v2_target_politician_to_person.xlsx\n",
            "test.csv\n",
            "train.csv\n",
            "val.csv\n",
            "xlmr_multitask_out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/drive/MyDrive/akmal_fyp/xlmr_multitask_out -type f \\( -name \"model.safetensors\" -o -name \"pytorch_model.bin\" \\)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2-mVXAtwIeJ",
        "outputId": "86f83798-968d-452e-9b95-feaf5d29e113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/akmal_fyp/xlmr_multitask_out/checkpoint-4017/model.safetensors\n",
            "/content/drive/MyDrive/akmal_fyp/xlmr_multitask_out/checkpoint-8034/model.safetensors\n",
            "/content/drive/MyDrive/akmal_fyp/xlmr_multitask_out/checkpoint-12051/model.safetensors\n",
            "/content/drive/MyDrive/akmal_fyp/xlmr_multitask_out/best_model/model.safetensors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install flask safetensors transformers\n"
      ],
      "metadata": {
        "id": "9ATGr5DQwpg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/app2.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBuI7CVDwuBa",
        "outputId": "b260b77d-e62e-4d12-d73f-c56fc280166e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tokenizer...\n",
            "Loading model architecture...\n",
            "2025-12-30 10:17:39.843539: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-30 10:17:39.857394: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-30 10:17:39.920009: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767089859.967821   25856 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767089859.979974   25856 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767089860.010002   25856 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767089860.010077   25856 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767089860.010087   25856 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767089860.010096   25856 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-30 10:17:40.020166: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "Loading model weights...\n",
            "Model loaded successfully ✅\n",
            " * Serving Flask app 'app2'\n",
            " * Debug mode: off\n",
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "Exception ignored in: <module 'threading' from '/usr/lib/python3.12/threading.py'>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1575, in _shutdown\n",
            "    def _shutdown():\n",
            "    \n",
            "KeyboardInterrupt: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Start Flask in background\n",
        "os.system(\"python /content/app2.py &\")\n",
        "\n",
        "# Open public tunnel\n",
        "print(ngrok.connect(5000))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "TYUcnBmS0uDL",
        "outputId": "5cd2eb9c-ddb2-47db-b677-321b73402c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-12-30T10:37:39+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-12-30T10:37:39+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-12-30T10:37:39+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1258081947.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Open public tunnel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Opening tunnel named: {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m     \u001b[0mapi_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ngrok_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_ngrok_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0minstall_ngrok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36mget_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_current_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrok_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_start_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36m_start_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             raise PyngrokNgrokError(f\"The ngrok process errored on start: {ngrok_process.startup_error}.\",\n\u001b[0m\u001b[1;32m    448\u001b[0m                                     \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                                     ngrok_process.startup_error)\n",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /content/cloudflared\n",
        "!chmod +x /content/cloudflared\n"
      ],
      "metadata": {
        "id": "_jmeVSOO1-lS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/cloudflared --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXBBYUQL2BlW",
        "outputId": "ee2b08b6-7ca9-4f79-87e6-38aab816dca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cloudflared version 2025.11.1 (built 2025-11-07-16:59 UTC)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/app2.py &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LbnZK5k2Qsm",
        "outputId": "b295ad68-271d-45ec-ee07-d49fb6a4afae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tokenizer...\n",
            "Loading model architecture...\n",
            "2025-12-30 10:41:32.280888: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-30 10:41:32.286227: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-30 10:41:32.298909: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767091292.318611   31723 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767091292.324582   31723 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767091292.340921   31723 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767091292.340960   31723 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767091292.340965   31723 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767091292.340970   31723 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-30 10:41:32.345920: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "Loading model weights...\n",
            "Model loaded successfully ✅\n",
            " * Serving Flask app 'app2'\n",
            " * Debug mode: off\n",
            "Address already in use\n",
            "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/cloudflared tunnel --url http://127.0.0.1:5000 --no-autoupdate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdTooeTW2YzL",
        "outputId": "e8bf2c7b-69f5-4cdd-b5ff-0c53a5fdc190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-12-30T10:42:05Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-12-30T10:42:05Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m |  https://pierre-rentals-union-prepare.trycloudflare.com                                    |\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.11.1 (Checksum 991dffd8889ee9f0147b6b48933da9e4407e68ea8c6d984f55fa2d3db4bb431d)\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.9, GoArch: amd64\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://127.0.0.1:5000]\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 064eb5f4-7433-4e81-890b-b0a582a75c9e\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-12-30T10:42:09Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.233\n",
            "2025/12/30 10:42:09 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-12-30T10:42:10Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0mb7c567cd-2464-492c-85fb-80b68ec7dd21 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.233 \u001b[36mlocation=\u001b[0mlax01 \u001b[36mprotocol=\u001b[0mquic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/drive/MyDrive/akmal_fyp/xlmr_multitask_out -maxdepth 2 -type f \\( -name \"model.safetensors\" -o -name \"pytorch_model.bin\" \\)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQc73K5VvGtq",
        "outputId": "76526da8-7637-4d45-8bfe-4667d5f08169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "find: ‘/content/drive/MyDrive/akmal_fyp/xlmr_multitask_out’: No such file or directory\n"
          ]
        }
      ]
    }
  ]
}